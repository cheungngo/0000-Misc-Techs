---
title: "20181022 Web scraping in multiple pages"
author: "cheungngo"
date: "22 October 2018"
output: word_document
---

```{r, message=FALSE}
library(rvest)
```

### Other pre-requisites

```{r, message=FALSE}
# General-purpose data wrangling
library(tidyverse)
```

### List of urls using str_c()

We are here using the google scholar  

```{r}
# For example we are searching for 'schizophrenia' + 'memantine'
url1 = 'https://scholar.google.com.hk/scholar?start='
url2 = '&q=schizophrenia+memantine+randomized+controlled+trial&hl=en&as_sdt=0,5'
start = (1:(8420/10))*10-10
list_of_url = str_c(url1,start,url2)
list_of_url[1:5]
```

### Getting the hyperlinks: html_attr('href') and unique()

Using the Selector Gadget we cannot find any specific identifiers for the title / other details of the papers  

In this case we would use the highlight on the title (And in this case the hyperlinks would be duplicated)

```{r}
get_hyperlink = function(url) {
  url %>%
    read_html() %>%
    html_nodes('.gs_rt a') %>%
    html_attr('href')
}
```

### Getting the title and others

```{r}
get_title = function(url) {
  url %>%
    read_html() %>%
    html_nodes('.gs_rt a') %>%
    html_text()
}
```

```{r}
get_author = function(url) {
  author = url %>%
    read_html() %>%
    html_nodes('.gs_a') %>%
    html_text()
  author = gsub(',.*','',author)
  return(author)
}
```

```{r}
get_all = function(url) {
  title = get_title(url)
  author = get_author(url)
  all = data.frame(Title = title,
                   Author = author)
}
```


```{r}
testing = list_of_url[1:5] %>%
  map(get_all) %>%
  bind_rows() 
testing[1:5,]
```

```{r}
write_tsv('testing.tsv')
```

